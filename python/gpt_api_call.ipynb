{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\rapto\\miniconda3\\envs\\ttds\\lib\\site-packages (from wikipedia) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rapto\\miniconda3\\envs\\ttds\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rapto\\miniconda3\\envs\\ttds\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rapto\\miniconda3\\envs\\ttds\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rapto\\miniconda3\\envs\\ttds\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=ce5a4224f1902f8ac47cf9dc628ab77e9869a4e43f25780039b87ca40698c4f0\n",
      "  Stored in directory: c:\\users\\rapto\\appdata\\local\\pip\\cache\\wheels\\c2\\46\\f4\\caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
      "Successfully installed beautifulsoup4-4.10.0 soupsieve-2.3.1 wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Morocco, officially the Kingdom of Morocco, is the northwesternmost country in the Maghreb region of North Africa. It overlooks the Mediterranean Sea to the north and the Atlantic Ocean to the west, and has land borders with Algeria to the east, and the disputed territory of Western Sahara to the south.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wikipedia\n",
    "wikipedia.summary(\"Morocco\", sentences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "API_TOKEN = \"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\"\n",
    "API_URL = \"https://api-inference.huggingface.co/models/EleutherAI/gpt-j-6B\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_term' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\TTDS-G35-CW3\\python\\gpt_api_call.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/TTDS-G35-CW3/python/gpt_api_call.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mwikipedia\u001b[39m.\u001b[39msummary(\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m, sentences\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mQ: \u001b[39m\u001b[39m{\u001b[39;00msearch_term\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mA:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'search_term' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{wikipedia.summary('0', sentences=10)}\\n\\nQ: {search_term}\\nA:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia.summary()\n",
    "s = str(requests.get(f\"http://en.wikipedia.org/?curid={10}\").content)#, headers=headers#, json=payload)\n",
    "result = re.search('<title>(.*)</title>', s).group(1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"What is the capital of Morocco?\"\n",
    "output = query({\n",
    "\t\"inputs\": f\"{wikipedia.summary('Morocco', sentences=1)}\\nQ: {search_term}\\nA:\",\n",
    "\t# \"inputs\": f\"Q: {search_term}\\nA:\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0][\"generated_text\"].split(\"\\nA:\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[0][\"generated_text\"].split(\"A:\")[-1].split(\"\\n\")[0])\n",
    "\n",
    "re.search(\n",
    "    '\\nA:(.*)\\n|Q:', \n",
    "    output[0][\"generated_text\"]\n",
    "    ).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = json.dumps(output)\n",
    "out = json.loads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit = \"Hello\"\n",
    "desc = \"\"\n",
    "try:\n",
    "    desc = wikipedia.summary(hit, sentences=3)\n",
    "except wikipedia.exceptions.PageError:\n",
    "    try:\n",
    "        wikipedia.summary(wikipedia.suggest(hit), sentences=3)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        pass\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.summary(\"Autism\", sentences=3, auto_suggest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\TTDS-G35-CW3\\python\\gpt_api_call.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/TTDS-G35-CW3/python/gpt_api_call.ipynb#ch0000012?line=0'>1</a>\u001b[0m req \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttp://en.wikipedia.org/?curid=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m1023\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TTDS-G35-CW3/python/gpt_api_call.ipynb#ch0000012?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m req\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TTDS-G35-CW3/python/gpt_api_call.ipynb#ch0000012?line=2'>3</a>\u001b[0m     hit \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(req\u001b[39m.\u001b[39mcontent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "req = requests.get(f\"http://en.wikipedia.org/?curid={1023}\")\n",
    "if req.status_code == 200:\n",
    "    hit = str(req.content)\n",
    "    hit = re.search('<title>(.*)</title>', hit).group(1) \n",
    "print(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"BBC News takes a look back at some of the most memorable quotes from this year's Eurovision Song Contest.\"}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str(req.content)\n",
    "import requests\n",
    "def query_hugging_face(payload):\n",
    "    API_TOKEN = \"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\"\n",
    "    # API_URL = \"https://api-inference.huggingface.co/models/EleutherAI/gpt-j-6B\"\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/google/pegasus-xsum\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "prompt = \"text_to_summarise\"\n",
    "output = query_hugging_face({\n",
    "    \"inputs\": prompt,\n",
    "})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(output))\n",
    "print(\"yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search('<h1 id=\"firstHeading\" class=\"firstHeading mw-first-heading\">(.*)</h1>', str(req.content)).group(1)\n",
    "# re.search('wgTitle:(.*),', hit).group(1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'desc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14212/661200183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdesc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'desc' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "title = \"Artifical intelligence\"\n",
    "# API_URL = \"https://en.wikipedia.org/w/api.php?format=json&origin=*&action=query&prop=extracts&exintro=1&explaintext=1&titles=\" + title.replace(\" \", \"%20\")\n",
    "API_URL = \"https://en.wikipedia.org/w/api.php?format=json&origin=*&action=query&prop=extracts&exintro=1&explaintext=1&\" + title.replace(\" \", \"%20\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(API_URL).json()[\"query\"][\"pages\"]\n",
    "    pid = list(response.keys())[0]\n",
    "    desc = response[pid][\"extract\"]\n",
    "except KeyError:\n",
    "    pass\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(API_URL).json()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "103b48ebf1aa2242c051892b45e13b26f3e433ba168cde98ac0c97b247123e4d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
